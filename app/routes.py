from __future__ import annotations

from datetime import datetime
from typing import List, Optional

import pandas as pd
from fastapi import File, Request, UploadFile
from fastapi.responses import HTMLResponse, RedirectResponse

from .analytics import analyze_dataset, prediction_summary, transform_single_record
from .csv_utils import read_uploaded_dataframe
from .forms import build_context, parse_form_to_record
from .supabase_service import ingest_dataset
import logging
logger = logging.getLogger(__name__)

from fastapi.responses import FileResponse
from reportlab.lib import colors
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, KeepTogether, PageBreak
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont
from reportlab.pdfbase.ttfonts import TTFont
import os
import tempfile
from bs4 import BeautifulSoup

def register_routes(app) -> None:
    templates = app.state.templates

    @app.get("/", response_class=HTMLResponse)
    async def upload_page(request: Request) -> HTMLResponse:
        store = app.state.store
        try:
            context = store.ensure_context()
        except RuntimeError as exc:
            return templates.TemplateResponse(
                "index.html",
                {
                    "request": request,
                    "result": None,
                    "error": str(exc),
                    "notifications": [],
                    "filename": None,
                    "model_ready": False,
                    "prediction": None,
                    "prediction_error": None,
                    "input_metadata": [],
                    "importance_image": None,
                    "top_features": [],
                    "rf_visuals": {},
                },
            )

        notifications = store.last_analysis["notifications"] if store.last_analysis else []
        return templates.TemplateResponse(
            "index.html",
            build_context(
                request,
                store=store,
                context=context,
                result=store.last_analysis,
                error=None,
                notifications=notifications,
            ),
        )

    
    @app.get("/analyze")
    async def reroute_get_analyze():
        return RedirectResponse(url="/", status_code=302)


    @app.post("/analyze", response_class=HTMLResponse)
    async def analyze_csv(request: Request, file: UploadFile = File(...)) -> HTMLResponse:
        store = app.state.store
        templates = app.state.templates
        try:
            context = store.ensure_context()
        except RuntimeError as exc:
            return templates.TemplateResponse(
                "index.html",
                {
                    "request": request,
                    "result": store.last_analysis,
                    "error": str(exc),
                    "notifications": store.last_analysis["notifications"] if store.last_analysis else [],
                    "filename": None,
                    "model_ready": False,
                    "prediction": None,
                    "prediction_error": None,
                    "input_metadata": [],
                    "importance_image": None,
                    "top_features": [],
                    "rf_visuals": {},
                },
            )

        if not file.filename.lower().endswith(".csv"):
            return templates.TemplateResponse(
                "index.html",
                build_context(
                    request,
                    store=store,
                    context=context,
                    result=store.last_analysis,
                    error="–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV.",
                    notifications=store.last_analysis["notifications"] if store.last_analysis else [],
                ),
            )

        content = await file.read()

        try:
            dataframe = read_uploaded_dataframe(content)
            dataframe.attrs["source_filename"] = file.filename
        except Exception as exc:
            return templates.TemplateResponse(
                "index.html",
                build_context(
                    request,
                    store=store,
                    context=context,
                    result=store.last_analysis,
                    error=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV: {exc}",
                    notifications=store.last_analysis["notifications"] if store.last_analysis else [],
                ),
            )
        filenames: List[str] = []
        supabase_warning: Optional[str] = None
        client = store.supabase_client
        table_name = store.settings.supabase_table

        if client is not None and table_name:
            try:
                if "." in table_name:
                    schema_name, table_name_only = table_name.split(".", maxsplit=1)
                    table_query = client.schema(schema_name).table(table_name_only)
                else:
                    table_query = client.table(table_name)
                response = table_query.select("filename").execute()
                select_result = getattr(response, "data", None) or []
                filenames = [
                    item.get("filename")
                    for item in select_result
                    if isinstance(item, dict) and item.get("filename")
                ]
                logger.info("–§–∞–π–ª %s –Ω–∞–π–¥–µ–Ω –≤ Supabase —Ç–∞–±–ª–∏—Ü–µ %s.", file.filename, table_name)
            except Exception as exc:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü–µ %s: %s", table_name, exc)
                supabase_warning = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏–∑ Supabase: {exc}"
        else:
            logger.info("Supabase –∫–ª–∏–µ–Ω—Ç –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤.")

        def merge_notifications(base_notifications: Optional[List[str]]) -> List[str]:
            merged = list(base_notifications or [])
            if supabase_warning:
                merged.append(supabase_warning)
            return merged

        if file.filename not in filenames:
            try:
                analysis, storage_df = analyze_dataset(dataframe, context, store)
            except Exception as exc:
                return templates.TemplateResponse(
                    "index.html",
                    build_context(
                        request,
                        store=store,
                        context=context,
                        result=store.last_analysis,
                        error=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–∞–Ω–Ω—ã—Ö: {exc}",
                        notifications=merge_notifications(
                            store.last_analysis["notifications"] if store.last_analysis else []
                        ),
                    ),
                )
            ingest_dataset(store, storage_df, file.filename, source="csv")
            store.last_analysis = analysis
            store.current_metadata = analysis["metadata"]

            return templates.TemplateResponse(
                "index.html",
                build_context(
                    request,
                    store=store,
                    context=context,
                    result=analysis,
                    error=None,
                    notifications=merge_notifications(analysis["notifications"]),
                    filename=file.filename,
                ),
            )
        else:
            return templates.TemplateResponse(
                "index.html",
                build_context(
                    request,
                    store=store,
                    context=context,
                    result=None,
                    error="File is already uploaded",
                    notifications=merge_notifications(None),
                    filename=file.filename,
                ),
            ) 

    @app.post("/predict", response_class=HTMLResponse)
    async def predict_single(request: Request, file: UploadFile = File(...)) -> HTMLResponse:
        store = app.state.store
        templates = app.state.templates
        try:
            context = store.ensure_context()
        except RuntimeError as exc:
            return templates.TemplateResponse(
                "index.html",
                {
                    "request": request,
                    "result": store.last_analysis,
                    "error": str(exc),
                    "notifications": store.last_analysis["notifications"] if store.last_analysis else [],
                    "filename": None,
                    "model_ready": False,
                    "prediction": None,
                    "prediction_error": None,
                    "input_metadata": [],
                    "importance_image": None,
                    "top_features": [],
                    "rf_visuals": {},
                },
            )

        if not file.filename.lower().endswith(".csv"):
            return templates.TemplateResponse(
                "index.html",
                build_context(
                    request,
                    store=store,
                    context=context,
                    result=store.last_analysis,
                    error=None,
                    notifications=store.last_analysis["notifications"] if store.last_analysis else [],
                    prediction=None,
                    prediction_error="–î–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Å –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π.",
                ),
            )

        content = await file.read()
        try:
            dataframe = read_uploaded_dataframe(content)
            dataframe.attrs["source_filename"] = file.filename
        except Exception as exc:
            return templates.TemplateResponse(
                "index.html",
                build_context(
                    request,
                    store=store,
                    context=context,
                    result=store.last_analysis,
                    error=None,
                    notifications=store.last_analysis["notifications"] if store.last_analysis else [],
                    prediction=None,
                    prediction_error=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞: {exc}",
                ),
            )

        if dataframe.empty or len(dataframe) != 1:
            return templates.TemplateResponse(
                "index.html",
                build_context(
                    request,
                    store=store,
                    context=context,
                    result=store.last_analysis,
                    error=None,
                    notifications=store.last_analysis["notifications"] if store.last_analysis else [],
                    prediction=None,
                    prediction_error="CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ä–æ–≤–Ω–æ –æ–¥–Ω—É –∑–∞–ø–∏—Å—å.",
                ),
            )

        try:
            features, prep_notifications = transform_single_record(dataframe, context)
        except Exception as exc:
            return templates.TemplateResponse(
                "index.html",
                build_context(
                    request,
                    store=store,
                    context=context,
                    result=store.last_analysis,
                    error=None,
                    notifications=store.last_analysis["notifications"] if store.last_analysis else [],
                    prediction=None,
                    prediction_error=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å: {exc}",
                ),
            )

        prediction = prediction_summary(features, context)
        prediction["preview_html"] = dataframe.to_html(index=False, classes="preview-table")
        prediction["preprocessing_notes"] = prep_notifications
        prediction["source"] = "csv"

        storage_df = dataframe.copy()
        storage_df["predicted_anomaly"] = prediction["anomaly_label"]
        storage_df["is_suspicious"] = int(prediction["suspicious"])
        storage_df["analysis_run_at"] = datetime.utcnow().isoformat()
        storage_df["source_filename"] = file.filename
        ingest_dataset(store, storage_df, file.filename, source="single_csv_prediction")

        return templates.TemplateResponse(
            "index.html",
            build_context(
                request,
                store=store,
                context=context,
                result=store.last_analysis,
                error=None,
                notifications=store.last_analysis["notifications"] if store.last_analysis else [],
                prediction=prediction,
                prediction_error=None,
            ),
        )

    @app.post("/predict-form", response_class=HTMLResponse)
    async def predict_from_form(request: Request) -> HTMLResponse:
        store = app.state.store
        templates = app.state.templates
        try:
            context = store.ensure_context()
        except RuntimeError as exc:
            return templates.TemplateResponse(
                "index.html",
                {
                    "request": request,
                    "result": store.last_analysis,
                    "error": str(exc),
                    "notifications": store.last_analysis["notifications"] if store.last_analysis else [],
                    "filename": None,
                    "model_ready": False,
                    "prediction": None,
                    "prediction_error": None,
                    "input_metadata": [],
                    "importance_image": None,
                    "top_features": [],
                    "rf_visuals": {},
                },
            )

        form_data = await request.form()
        form_dict = dict(form_data)

        metadata = store.current_metadata or store.generate_metadata(None)

        try:
            record = parse_form_to_record(form_dict, metadata)
        except Exception as exc:
            return templates.TemplateResponse(
                "index.html",
                build_context(
                    request,
                    store=store,
                    context=context,
                    result=store.last_analysis,
                    error=None,
                    notifications=store.last_analysis["notifications"] if store.last_analysis else [],
                    prediction=None,
                    prediction_error=f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è —Ñ–æ—Ä–º—ã: {exc}",
                    form_values=form_dict,
                ),
            )

        record_df = pd.DataFrame([record])
        try:
            features, prep_notifications = transform_single_record(record_df, context)
        except Exception as exc:
            return templates.TemplateResponse(
                "index.html",
                build_context(
                    request,
                    store=store,
                    context=context,
                    result=store.last_analysis,
                    error=None,
                    notifications=store.last_analysis["notifications"] if store.last_analysis else [],
                    prediction=None,
                    prediction_error=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å: {exc}",
                    form_values=form_dict,
                ),
            )

        prediction = prediction_summary(features, context)
        prediction["preview_html"] = record_df.to_html(index=False, classes="preview-table")
        prediction["preprocessing_notes"] = prep_notifications
        prediction["source"] = "form"

        storage_df = record_df.copy()
        storage_df["predicted_anomaly"] = prediction["anomaly_label"]
        storage_df["is_suspicious"] = int(prediction["suspicious"])
        storage_df["analysis_run_at"] = datetime.utcnow().isoformat()
        storage_df["source_filename"] = "form_submission"
        # ingest_dataset(store, storage_df, "form_submission", source="form_submission")

        return templates.TemplateResponse(
            "index.html",
            build_context(
                request,
                store=store,
                context=context,
                result=store.last_analysis,
                error=None,
                notifications=store.last_analysis["notifications"] if store.last_analysis else [],
                prediction=prediction,
                prediction_error=None,
                form_values=form_dict,
            ),
        )

    MAX_CELL_LENGTH = 50  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —è—á–µ–π–∫–µ

    def truncate_text(text: str, max_len: int = MAX_CELL_LENGTH) -> str:
        if len(text) > max_len:
            return text[:max_len-3] + "..."
        return text

    @app.get("/export-pdf")
    async def export_pdf(request: Request):
        store = request.app.state.store
        result = store.last_analysis
        if not result:
            return HTMLResponse("<h3>–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞</h3>")

        font_path = os.path.join(os.path.dirname(__file__), "fonts", "DejaVuSans.ttf")
        if not os.path.exists(font_path):
            return HTMLResponse("<h3>–§–∞–π–ª —à—Ä–∏—Ñ—Ç–∞ DejaVuSans.ttf –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–º–µ—Å—Ç–∏—Ç–µ –µ–≥–æ –≤ –ø–∞–ø–∫—É /fonts —Ä—è–¥–æ–º —Å routes.py</h3>")
        pdfmetrics.registerFont(TTFont("DejaVuSans", font_path))

        tmp_pdf = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
        doc = SimpleDocTemplate(tmp_pdf.name, pagesize=A4, rightMargin=30, leftMargin=30, topMargin=30, bottomMargin=30)
        available_width = doc.width

        styles = getSampleStyleSheet()
        styles.add(ParagraphStyle(name="TitleRu", fontName="DejaVuSans", fontSize=18, leading=22, alignment=1, textColor=colors.darkblue))
        styles.add(ParagraphStyle(name="Heading", fontName="DejaVuSans", fontSize=14, leading=18, textColor=colors.darkred))
        styles.add(ParagraphStyle(name="Body", fontName="DejaVuSans", fontSize=10, leading=12))

        story = []

        # === –ó–∞–≥–æ–ª–æ–≤–æ–∫ ===
        story.append(Paragraph("üìä –û—Ç—á—ë—Ç –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É", styles["TitleRu"]))
        story.append(Spacer(1, 16))

        # === –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ ===
        story.append(Paragraph("–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞:", styles["Heading"]))
        data = [["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ"]]
        data.append(["–û–±—ä—ë–º —Å—Ç—Ä–æ–∫", truncate_text(str(result.get("records", "-")))])
        data.append(["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", truncate_text(str(result.get("columns", "-")))])
        if result.get("prediction_counts"):
            data.append(["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –º–æ–¥–µ–ª–∏", truncate_text(str(len(result["prediction_counts"])))])

        metrics_table = Table([[Paragraph(str(c), styles["Body"]) for c in row] for row in data],
                            hAlign="LEFT", colWidths=[200, 250])
        metrics_table.setStyle(TableStyle([
            ("GRID", (0,0), (-1,-1), 0.5, colors.grey),
            ("BACKGROUND", (0,0), (-1,0), colors.lightblue),
            ("ALIGN", (0,0), (-1,0), "CENTER"),
            ("VALIGN", (0,0), (-1,-1), "TOP"),
        ]))
        story.append(metrics_table)
        story.append(Spacer(1, 12))

        # === –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫) ===
        if result.get("preview_html"):
            story.append(Paragraph("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫):", styles["Heading"]))
            soup = BeautifulSoup(result["preview_html"], "html.parser")
            rows = soup.find_all("tr")
            table_data = []
            for row in rows[:11]:  # –∑–∞–≥–æ–ª–æ–≤–æ–∫ + 10 —Å—Ç—Ä–æ–∫
                cols = [truncate_text(c.get_text(strip=True)) for c in row.find_all(["th","td"])]
                cols = [Paragraph(c, styles["Body"]) for c in cols]
                table_data.append(cols)

            if table_data:
                num_cols = len(table_data[0])
                if num_cols == 0:
                    num_cols = 1
                col_width = max(40, available_width / num_cols)
                total_width = col_width * num_cols
                if total_width > available_width:
                    col_width = available_width / num_cols
                col_widths = [col_width] * num_cols
                preview_table = Table(table_data, repeatRows=1, colWidths=col_widths)
                preview_table.setStyle(TableStyle([
                    ("GRID", (0,0), (-1,-1), 0.25, colors.grey),
                    ("BACKGROUND", (0,0), (-1,0), colors.lightgrey),
                    ("VALIGN", (0,0), (-1,-1), "TOP"),
                    ("LEFTPADDING", (0,0), (-1,-1), 2),
                    ("RIGHTPADDING", (0,0), (-1,-1), 2),
                    ("TOPPADDING", (0,0), (-1,-1), 2),
                    ("BOTTOMPADDING", (0,0), (-1,-1), 2),
                ]))
                story.append(preview_table)
                story.append(Spacer(1, 12))

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
        if result.get("prediction_counts"):
            story.append(PageBreak())
            story.append(Paragraph("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –º–æ–¥–µ–ª–∏:", styles["Heading"]))
            class_data = [["–ö–ª–∞—Å—Å", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"]]
            for cls, cnt in result["prediction_counts"].items():
                class_data.append([str(cls), str(cnt)])
            class_table = Table(class_data, hAlign="LEFT", colWidths=[200, 200])
            class_table.setStyle(TableStyle([
                ("GRID", (0,0), (-1,-1), 0.5, colors.grey),
                ("BACKGROUND", (0,0), (-1,0), colors.lightblue),
                ("FONTNAME", (0,0), (-1,-1), "DejaVuSans"),
                ("FONTSIZE", (0,0), (-1,-1), 10),
                ("ALIGN", (0,0), (-1,0), "CENTER"),
                ("VALIGN", (0,0), (-1,-1), "MIDDLE"),
            ]))
            story.append(class_table)
            story.append(Spacer(1, 12))

        # === –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑—Ä—ã–≤ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–µ—Ä–µ–¥ —Å—Ä–µ–¥–Ω–∏–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ ===
        if result.get("average_probabilities"):
            story.append(PageBreak())
            story.append(Paragraph("–°—Ä–µ–¥–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º:", styles["Heading"]))
            prob_data = [["–ö–ª–∞—Å—Å", "–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å"]]
            for label, prob in result["average_probabilities"].items():
                prob_data.append([truncate_text(str(label)), f"{prob*100:.2f}%"])

            prob_table = Table([[Paragraph(str(c), styles["Body"]) for c in row] for row in prob_data],
                            hAlign="LEFT", colWidths=[200, 250])
            prob_table.setStyle(TableStyle([
                ("GRID", (0,0), (-1,-1), 0.5, colors.grey),
                ("BACKGROUND", (0,0), (-1,0), colors.lightblue),
                ("ALIGN", (0,0), (-1,0), "CENTER"),
                ("VALIGN", (0,0), (-1,-1), "TOP"),
            ]))
            story.append(prob_table)
            story.append(Spacer(1, 12))

        doc.build(story)
        return FileResponse(tmp_pdf.name, filename="dataset_analysis.pdf", media_type="application/pdf")
